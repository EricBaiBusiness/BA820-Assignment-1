{"cells":[{"cell_type":"markdown","metadata":{"id":"Yh-uxVzfBpxB"},"source":["# Assignment Prep - Association Rule Mining\n","\n","We will use [The Bread Basket Dataset](https://www.kaggle.com/datasets/mittalvasu95/the-bread-basket). The dataset belongs to \"The Bread Basket\" a bakery located in Edinburgh.\n","\n","Opendatasets is a python package which makes it easier to import datasets from Kaggle.\n","\n","Prerequisites:\n","\n","- Kaggle Account (preferrably using BU email ID)\n","\n","Run the following two cells. In the second cell you will be prompted to enter username and key.\n","\n","Use this link - https://www.kaggle.com/settings/account\n","\n","- On the right side of your screen you can see your username.\n","- Scroll down a bit, you will see an API subheading. Click on '**Create new token**'.\n","- It should automatically download a .json file containing your username and key.\n","- Copy paste them into the output of the 2nd cell.\n","\n","Your dataset will be visible in the folders tab on the left side of your colab screen!!"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8-0hmEsb-Iwa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opendatasets in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (0.1.22)\n","Requirement already satisfied: tqdm in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from opendatasets) (4.65.0)\n","Requirement already satisfied: kaggle in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from opendatasets) (1.6.4)\n","Requirement already satisfied: click in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from opendatasets) (8.0.4)\n","Requirement already satisfied: six>=1.10 in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (1.16.0)\n","Requirement already satisfied: certifi in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (2.8.2)\n","Requirement already satisfied: requests in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (2.31.0)\n","Requirement already satisfied: python-slugify in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (5.0.2)\n","Requirement already satisfied: urllib3 in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (1.26.16)\n","Requirement already satisfied: bleach in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (4.1.0)\n","Requirement already satisfied: packaging in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from bleach->kaggle->opendatasets) (23.0)\n","Requirement already satisfied: webencodings in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from bleach->kaggle->opendatasets) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from requests->kaggle->opendatasets) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/hakukazuho/anaconda3/lib/python3.11/site-packages (from requests->kaggle->opendatasets) (3.4)\n"]}],"source":["!pip install opendatasets"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"aFsH7xes9QWz"},"outputs":[],"source":["import opendatasets as od\n","import pandas as pd\n","import numpy as np\n","\n","# od.download(\n","#     \"https://www.kaggle.com/datasets/mittalvasu95/the-bread-basket\")"]},{"cell_type":"markdown","metadata":{"id":"xg840G7ME8HK"},"source":["### This cell is for installing any python packages you want to use"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YdWIbYUaFJ7X"},"outputs":[],"source":["!pip install your-package-name"]},{"cell_type":"markdown","metadata":{"id":"DTzJ2QHcEGrQ"},"source":["# Question 1 **(5 Points)**\n","\n","Find the top 5 *single* item recommendations based on any *single* item purchases in the bakery. These recommendations will be used to optimally place the two items within reach from to each other.\n","\n","Use the apriori algorithm with a reasonable minimum support (Justify your choice).\n","\n","By what percentage has the apriori method reduced the computational cost of solving this query?"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>antecedents</th>\n","      <th>consequents</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>(Coffee)</td>\n","      <td>(Bread)</td>\n","      <td>0.090016</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>(Coffee)</td>\n","      <td>(Cake)</td>\n","      <td>0.054728</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>(Coffee)</td>\n","      <td>(Tea)</td>\n","      <td>0.049868</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>(Coffee)</td>\n","      <td>(Pastry)</td>\n","      <td>0.047544</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>(Coffee)</td>\n","      <td>(Sandwich)</td>\n","      <td>0.038246</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>(Bread)</td>\n","      <td>(Coffee)</td>\n","      <td>0.090016</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>(Cake)</td>\n","      <td>(Coffee)</td>\n","      <td>0.054728</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>(Tea)</td>\n","      <td>(Coffee)</td>\n","      <td>0.049868</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>(Pastry)</td>\n","      <td>(Coffee)</td>\n","      <td>0.047544</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>(Sandwich)</td>\n","      <td>(Coffee)</td>\n","      <td>0.038246</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  antecedents consequents   support\n","0    (Coffee)     (Bread)  0.090016\n","1    (Coffee)      (Cake)  0.054728\n","2    (Coffee)       (Tea)  0.049868\n","3    (Coffee)    (Pastry)  0.047544\n","4    (Coffee)  (Sandwich)  0.038246\n","5     (Bread)    (Coffee)  0.090016\n","6      (Cake)    (Coffee)  0.054728\n","7       (Tea)    (Coffee)  0.049868\n","8    (Pastry)    (Coffee)  0.047544\n","9  (Sandwich)    (Coffee)  0.038246"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","from mlxtend.preprocessing import TransactionEncoder\n","from mlxtend.frequent_patterns import apriori, association_rules\n","\n","df = pd.read_csv('bread basket.csv')\n","df_short = df[['Transaction', 'Item']]\n","\n","df_agg = df_short.groupby('Transaction')['Item'].agg(lambda x: ','.join(x.astype(str))).reset_index()\n","\n","data_column = df_agg.iloc[:, 1]\n","data = list(data_column.apply(lambda x: x.split(',')))\n","\n","encoder = TransactionEncoder()\n","\n","data_encoded = encoder.fit(data).transform(data)\n","df_encoded = pd.DataFrame(data_encoded, columns=encoder.columns_)\n","\n","frequent_itemsets = apriori(df_encoded, min_support=0.00001, use_colnames=True)\n","\n","rules = association_rules(frequent_itemsets, metric='support', min_threshold=0.01)\n","\n","rules_1_on_1 = rules[(rules['antecedents'].apply(lambda x: len(x)==1) & \n","                      rules['consequents'].apply(lambda x: len(x)==1))]\n","\n","rules_1_on_1_sorted = rules_1_on_1.sort_values(by='support', ascending=False).head(10)\n","\n","rules_1_on_1_unique = rules_1_on_1_sorted.groupby(['antecedents', 'consequents'])['support'].mean().reset_index()\n","rules_1_on_1_unique"]},{"cell_type":"markdown","metadata":{},"source":["As is shown in the table above, the top 5 itemsets with the highest support value are (from highest to lowest):\n","\n","1. Coffee & Bread\n","\n","2. Coffee & Cake\n","\n","3. Coffee & Tea\n","\n","4. Coffee & Pastry\n","\n","5. Coffee & Sandwich\n","\n","Thus I would recommend to place Coffee in the center of the other four items.\n","\n","In terms of support threshold choice in apriori, I intend to choose a low threshold because I plan to filter the dataset during the association rule and later steps, so it's good to set a low threshold to keep more data points at this point."]},{"cell_type":"markdown","metadata":{"id":"9C5IKg9ZFjmo"},"source":["# Question 2 **(5 Points)**\n","\n","Find out how/if the recommendations from the previous question change based on the time of the day. (morning, afternoon, evening). Comment on how similar/different the associations are."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hP7wUhjxF0UJ"},"outputs":[],"source":["# Build a pipeline to process the data\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ggUnvWqUGOQu"},"source":["# Question 3 **(10 Points)**\n","\n","Find out if the day of the week (i.e., Monday, Tuesday, ..) affects the customers' purchase patterns. Compute the top 3 most common item associations for each day. Comment on how similar/different the rules are.\n","\n","Use [to_datetime](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) and [dayofweek](https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.dayofweek.html) to generate the day of the week for any date."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C_-z1Y55Gc1I"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"L33cCelIGhrA"},"source":["# Question 4 **(8 Points)**\n","\n","For the items that are bought together in more than 500 transactions:\n","\n","1. for the sake of item promotion, suggest a strong rule that indicate that  the second item is *more likely than not* to be bought as well once the first one is bought.\n","2. Show a pair of items that seem to be ill-suited for being promoted together.\n","\n","Explain your answers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zd9xBv6qGwgx"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"zIdSdCzrG-OG"},"source":["# Question 5 **(2 Points)**\n","\n","Give the following rule from the dataset:\n","\n","(Valentine's card) -> (Tshirt)\n","\n","Find its lift, confidence, and support. Do these metrics support the claim that placing valentine cards next to the t-shirt stand will substantially  increase t-shirt sales? Explain your conclusion."]},{"cell_type":"markdown","metadata":{"id":"hmt9sLI4HFjU"},"source":["*Your answer goes here .... (i.e. edit this markdown cell by double clicking here)*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCAIsctAHJtq"},"outputs":[],"source":["# Python code if any"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
